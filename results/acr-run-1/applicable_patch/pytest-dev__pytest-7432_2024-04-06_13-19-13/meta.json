{
    "task_id": "pytest-dev__pytest-7432",
    "setup_info": {
        "repo_path": "/media/media0/yuntong/SWE-bench/testbed/pytest-dev__pytest/setup_pytest-dev__pytest__5.4",
        "env_name": "setup_pytest-dev__pytest__5.4",
        "pre_install": [],
        "install": "python -m pip install -e .",
        "test_cmd": "pytest -rA testing/test_skipping.py"
    },
    "task_info": {
        "instance_id": "pytest-dev__pytest-7432",
        "base_commit": "e6e300e729dd33956e5448d8be9a0b1540b4e53a",
        "hints_text": "Can I look into this one?\n@debugduck Sure!\nAwesome! I'll get started on it and open up a PR when I find it. I'm a bit new, so I'm still learning about the code base.",
        "created_at": "2020-06-29T21:51:15Z",
        "test_patch": "diff --git a/testing/test_skipping.py b/testing/test_skipping.py\n--- a/testing/test_skipping.py\n+++ b/testing/test_skipping.py\n@@ -235,6 +235,31 @@ def test_func2():\n             [\"*def test_func():*\", \"*assert 0*\", \"*1 failed*1 pass*\"]\n         )\n \n+    @pytest.mark.parametrize(\n+        \"test_input,expected\",\n+        [\n+            (\n+                [\"-rs\"],\n+                [\"SKIPPED [1] test_sample.py:2: unconditional skip\", \"*1 skipped*\"],\n+            ),\n+            (\n+                [\"-rs\", \"--runxfail\"],\n+                [\"SKIPPED [1] test_sample.py:2: unconditional skip\", \"*1 skipped*\"],\n+            ),\n+        ],\n+    )\n+    def test_xfail_run_with_skip_mark(self, testdir, test_input, expected):\n+        testdir.makepyfile(\n+            test_sample=\"\"\"\n+            import pytest\n+            @pytest.mark.skip\n+            def test_skip_location() -> None:\n+                assert 0\n+        \"\"\"\n+        )\n+        result = testdir.runpytest(*test_input)\n+        result.stdout.fnmatch_lines(expected)\n+\n     def test_xfail_evalfalse_but_fails(self, testdir):\n         item = testdir.getitem(\n             \"\"\"\n",
        "repo": "pytest-dev/pytest",
        "problem_statement": "skipping: --runxfail breaks pytest.mark.skip location reporting\npytest versions: 5.4.x, current master\r\n\r\nWhen `@pytest.mark.skip`/`skipif` marks are used to skip a test, for example\r\n\r\n```py\r\nimport pytest\r\n@pytest.mark.skip\r\ndef test_skip_location() -> None:\r\n    assert 0\r\n```\r\n\r\nthe expected skip location reported should point to the item itself, and this is indeed what happens when running with `pytest -rs`:\r\n\r\n```\r\nSKIPPED [1] test_it.py:3: unconditional skip\r\n```\r\n\r\nHowever, adding `pytest -rs --runxfail` breaks this:\r\n\r\n```\r\nSKIPPED [1] src/_pytest/skipping.py:238: unconditional skip\r\n```\r\n\r\nThe `--runxfail` is only about xfail and should not affect this at all.\r\n\r\n---\r\n\r\nHint: the bug is in `src/_pytest/skipping.py`, the `pytest_runtest_makereport` hook.\n",
        "version": "5.4",
        "FAIL_TO_PASS": [
            "testing/test_skipping.py::TestXFail::test_xfail_run_with_skip_mark[test_input1-expected1]"
        ],
        "PASS_TO_PASS": [
            "testing/test_skipping.py::TestBooleanCondition::test_skipif",
            "testing/test_skipping.py::TestBooleanCondition::test_skipif_noreason",
            "testing/test_skipping.py::TestBooleanCondition::test_xfail",
            "testing/test_skipping.py::TestEvaluation::test_marked_one_arg",
            "testing/test_skipping.py::TestEvaluation::test_marked_one_arg_twice",
            "testing/test_skipping.py::TestEvaluation::test_marked_one_arg_twice2",
            "testing/test_skipping.py::TestEvaluation::test_marked_one_arg_with_reason",
            "testing/test_skipping.py::TestEvaluation::test_marked_skipif_no_args",
            "testing/test_skipping.py::TestEvaluation::test_marked_skipif_with_boolean_without_reason",
            "testing/test_skipping.py::TestEvaluation::test_marked_skipif_with_invalid_boolean",
            "testing/test_skipping.py::TestEvaluation::test_marked_xfail_no_args",
            "testing/test_skipping.py::TestEvaluation::test_no_marker",
            "testing/test_skipping.py::TestEvaluation::test_skipif_class",
            "testing/test_skipping.py::TestSkip::test_arg_as_reason",
            "testing/test_skipping.py::TestSkip::test_only_skips_marked_test",
            "testing/test_skipping.py::TestSkip::test_skip_class",
            "testing/test_skipping.py::TestSkip::test_skip_no_reason",
            "testing/test_skipping.py::TestSkip::test_skip_with_reason",
            "testing/test_skipping.py::TestSkip::test_skips_on_false_string",
            "testing/test_skipping.py::TestSkip::test_strict_and_skip",
            "testing/test_skipping.py::TestSkipif::test_skipif_conditional",
            "testing/test_skipping.py::TestSkipif::test_skipif_reporting[\"hasattr(sys,",
            "testing/test_skipping.py::TestSkipif::test_skipif_reporting[True,",
            "testing/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[skipif-SKIP-skipped]",
            "testing/test_skipping.py::TestSkipif::test_skipif_reporting_multiple[xfail-XPASS-xpassed]",
            "testing/test_skipping.py::TestSkipif::test_skipif_using_platform",
            "testing/test_skipping.py::TestXFail::test_dynamic_xfail_no_run",
            "testing/test_skipping.py::TestXFail::test_dynamic_xfail_set_during_funcarg_setup",
            "testing/test_skipping.py::TestXFail::test_strict_sanity",
            "testing/test_skipping.py::TestXFail::test_strict_xfail[False]",
            "testing/test_skipping.py::TestXFail::test_strict_xfail[True]",
            "testing/test_skipping.py::TestXFail::test_strict_xfail_condition[False]",
            "testing/test_skipping.py::TestXFail::test_strict_xfail_condition[True]",
            "testing/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[false]",
            "testing/test_skipping.py::TestXFail::test_strict_xfail_default_from_file[true]",
            "testing/test_skipping.py::TestXFail::test_xfail_condition_keyword[False]",
            "testing/test_skipping.py::TestXFail::test_xfail_condition_keyword[True]",
            "testing/test_skipping.py::TestXFail::test_xfail_evalfalse_but_fails",
            "testing/test_skipping.py::TestXFail::test_xfail_imperative",
            "testing/test_skipping.py::TestXFail::test_xfail_imperative_in_setup_function",
            "testing/test_skipping.py::TestXFail::test_xfail_not_report_default",
            "testing/test_skipping.py::TestXFail::test_xfail_not_run_no_setup_run",
            "testing/test_skipping.py::TestXFail::test_xfail_not_run_xfail_reporting",
            "testing/test_skipping.py::TestXFail::test_xfail_raises[(AttributeError,",
            "testing/test_skipping.py::TestXFail::test_xfail_raises[TypeError-IndexError-*1",
            "testing/test_skipping.py::TestXFail::test_xfail_raises[TypeError-TypeError-*1",
            "testing/test_skipping.py::TestXFail::test_xfail_run_anyway",
            "testing/test_skipping.py::TestXFail::test_xfail_run_with_skip_mark[test_input0-expected0]",
            "testing/test_skipping.py::TestXFail::test_xfail_simple[False]",
            "testing/test_skipping.py::TestXFail::test_xfail_simple[True]",
            "testing/test_skipping.py::TestXFail::test_xfail_using_platform",
            "testing/test_skipping.py::TestXFail::test_xfail_xpass",
            "testing/test_skipping.py::TestXFail::test_xfail_xpassed",
            "testing/test_skipping.py::TestXFail::test_xfail_xpassed_strict",
            "testing/test_skipping.py::TestXFailwithSetupTeardown::test_failing_setup_issue9",
            "testing/test_skipping.py::TestXFailwithSetupTeardown::test_failing_teardown_issue9",
            "testing/test_skipping.py::test_default_markers",
            "testing/test_skipping.py::test_errors_in_xfail_skip_expressions",
            "testing/test_skipping.py::test_imperativeskip_on_xfail_test",
            "testing/test_skipping.py::test_importorskip",
            "testing/test_skipping.py::test_invalid_skip_keyword_parameter",
            "testing/test_skipping.py::test_mark_xfail_item",
            "testing/test_skipping.py::test_module_level_skip_error",
            "testing/test_skipping.py::test_module_level_skip_with_allow_module_level",
            "testing/test_skipping.py::test_relpath_rootdir",
            "testing/test_skipping.py::test_reportchars",
            "testing/test_skipping.py::test_reportchars_all",
            "testing/test_skipping.py::test_reportchars_all_error",
            "testing/test_skipping.py::test_reportchars_error",
            "testing/test_skipping.py::test_skip_not_report_default",
            "testing/test_skipping.py::test_skipif_class",
            "testing/test_skipping.py::test_skipped_folding",
            "testing/test_skipping.py::test_skipped_reasons_functional",
            "testing/test_skipping.py::test_summary_list_after_errors",
            "testing/test_skipping.py::test_xfail_item",
            "testing/test_skipping.py::test_xfail_skipif_with_globals",
            "testing/test_skipping.py::test_xfail_test_setup_exception"
        ],
        "environment_setup_commit": "678c1a0745f1cf175c442c719906a1f13e496910",
        "patch": "diff --git a/src/_pytest/skipping.py b/src/_pytest/skipping.py\n--- a/src/_pytest/skipping.py\n+++ b/src/_pytest/skipping.py\n@@ -291,7 +291,8 @@ def pytest_runtest_makereport(item: Item, call: CallInfo[None]):\n             else:\n                 rep.outcome = \"passed\"\n                 rep.wasxfail = xfailed.reason\n-    elif (\n+\n+    if (\n         item._store.get(skipped_by_mark_key, True)\n         and rep.skipped\n         and type(rep.longrepr) is tuple\n",
        "pr_link": "https://github.com/pytest-dev/pytest/pull/7432"
    }
}