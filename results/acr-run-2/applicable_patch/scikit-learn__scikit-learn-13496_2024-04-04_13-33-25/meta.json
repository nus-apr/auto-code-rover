{
    "task_id": "scikit-learn__scikit-learn-13496",
    "setup_info": {
        "repo_path": "/home/haifeng/projects/reverse-prompt/SWE-bench/testbed/scikit-learn__scikit-learn/setup_scikit-learn__scikit-learn__0.21",
        "env_name": "setup_scikit-learn__scikit-learn__0.21",
        "pre_install": [],
        "install": "python -m pip install -v --no-use-pep517 --no-build-isolation -e .",
        "test_cmd": "pytest --no-header -rA --tb=no -p no:cacheprovider sklearn/ensemble/tests/test_iforest.py"
    },
    "task_info": {
        "instance_id": "scikit-learn__scikit-learn-13496",
        "base_commit": "3aefc834dce72e850bff48689bea3c7dff5f3fad",
        "hints_text": "+1 to expose `warm_start` in `IsolationForest`, unless there was a good reason for not doing so in the first place. I could not find any related discussion in the IsolationForest PR #4163. ping @ngoix @agramfort?\nno objection\n\n>\n\nPR welcome @petibear. Feel\r\nfree to ping me when it\u2019s ready for reviews :).\nOK, I'm working on it then. \r\nHappy to learn the process (of contributing) here. ",
        "created_at": "2019-03-23T09:46:59Z",
        "test_patch": "diff --git a/sklearn/ensemble/tests/test_iforest.py b/sklearn/ensemble/tests/test_iforest.py\n--- a/sklearn/ensemble/tests/test_iforest.py\n+++ b/sklearn/ensemble/tests/test_iforest.py\n@@ -295,6 +295,28 @@ def test_score_samples():\n                        clf2.score_samples([[2., 2.]]))\n \n \n+@pytest.mark.filterwarnings('ignore:default contamination')\n+@pytest.mark.filterwarnings('ignore:behaviour=\"old\"')\n+def test_iforest_warm_start():\n+    \"\"\"Test iterative addition of iTrees to an iForest \"\"\"\n+\n+    rng = check_random_state(0)\n+    X = rng.randn(20, 2)\n+\n+    # fit first 10 trees\n+    clf = IsolationForest(n_estimators=10, max_samples=20,\n+                          random_state=rng, warm_start=True)\n+    clf.fit(X)\n+    # remember the 1st tree\n+    tree_1 = clf.estimators_[0]\n+    # fit another 10 trees\n+    clf.set_params(n_estimators=20)\n+    clf.fit(X)\n+    # expecting 20 fitted trees and no overwritten trees\n+    assert len(clf.estimators_) == 20\n+    assert clf.estimators_[0] is tree_1\n+\n+\n @pytest.mark.filterwarnings('ignore:default contamination')\n @pytest.mark.filterwarnings('ignore:behaviour=\"old\"')\n def test_deprecation():\n",
        "repo": "scikit-learn/scikit-learn",
        "problem_statement": "Expose warm_start in Isolation forest\nIt seems to me that `sklearn.ensemble.IsolationForest` supports incremental addition of new trees with the `warm_start` parameter of its parent class, `sklearn.ensemble.BaseBagging`.\r\n\r\nEven though this parameter is not exposed in `__init__()` , it gets inherited from `BaseBagging` and one can use it by changing it to `True` after initialization. To make it work, you have to also increment `n_estimators` on every iteration. \r\n\r\nIt took me a while to notice that it actually works, and I had to inspect the source code of both `IsolationForest` and `BaseBagging`. Also, it looks to me that the behavior is in-line with `sklearn.ensemble.BaseForest` that is behind e.g. `sklearn.ensemble.RandomForestClassifier`.\r\n\r\nTo make it more easier to use, I'd suggest to:\r\n* expose `warm_start` in `IsolationForest.__init__()`, default `False`;\r\n* document it in the same way as it is documented for `RandomForestClassifier`, i.e. say:\r\n```py\r\n    warm_start : bool, optional (default=False)\r\n        When set to ``True``, reuse the solution of the previous call to fit\r\n        and add more estimators to the ensemble, otherwise, just fit a whole\r\n        new forest. See :term:`the Glossary <warm_start>`.\r\n```\r\n* add a test to make sure it works properly;\r\n* possibly also mention in the \"IsolationForest example\" documentation entry;\r\n\n",
        "version": "0.21",
        "FAIL_TO_PASS": [
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_warm_start"
        ],
        "PASS_TO_PASS": [
            "sklearn/ensemble/tests/test_iforest.py::test_behaviour_param",
            "sklearn/ensemble/tests/test_iforest.py::test_deprecation",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_average_path_length",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works1[0.25-3]",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works1[auto-2]",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works2[0.25-3]",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_chunks_works2[auto-2]",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_error",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_parallel_regression",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_performance",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_sparse",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_subsampled_features",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_works[0.25]",
            "sklearn/ensemble/tests/test_iforest.py::test_iforest_works[auto]",
            "sklearn/ensemble/tests/test_iforest.py::test_max_samples_attribute",
            "sklearn/ensemble/tests/test_iforest.py::test_max_samples_consistency",
            "sklearn/ensemble/tests/test_iforest.py::test_recalculate_max_depth",
            "sklearn/ensemble/tests/test_iforest.py::test_score_samples"
        ],
        "environment_setup_commit": "7813f7efb5b2012412888b69e73d76f2df2b50b6",
        "patch": "diff --git a/sklearn/ensemble/iforest.py b/sklearn/ensemble/iforest.py\n--- a/sklearn/ensemble/iforest.py\n+++ b/sklearn/ensemble/iforest.py\n@@ -120,6 +120,12 @@ class IsolationForest(BaseBagging, OutlierMixin):\n     verbose : int, optional (default=0)\n         Controls the verbosity of the tree building process.\n \n+    warm_start : bool, optional (default=False)\n+        When set to ``True``, reuse the solution of the previous call to fit\n+        and add more estimators to the ensemble, otherwise, just fit a whole\n+        new forest. See :term:`the Glossary <warm_start>`.\n+\n+        .. versionadded:: 0.21\n \n     Attributes\n     ----------\n@@ -173,7 +179,8 @@ def __init__(self,\n                  n_jobs=None,\n                  behaviour='old',\n                  random_state=None,\n-                 verbose=0):\n+                 verbose=0,\n+                 warm_start=False):\n         super().__init__(\n             base_estimator=ExtraTreeRegressor(\n                 max_features=1,\n@@ -185,6 +192,7 @@ def __init__(self,\n             n_estimators=n_estimators,\n             max_samples=max_samples,\n             max_features=max_features,\n+            warm_start=warm_start,\n             n_jobs=n_jobs,\n             random_state=random_state,\n             verbose=verbose)\n",
        "pr_link": "https://github.com/scikit-learn/scikit-learn/pull/13496"
    }
}